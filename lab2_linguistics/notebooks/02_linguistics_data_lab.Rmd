---
title: "Lab 2 - Linguistics Data"
author: "Tiffany Tang"
date: "`r Sys.Date()`"
output: vthemes::vmodern
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)

source(here::here("R", "load-solution.R"))
source(here::here("R", "clean-solution.R"))
source(here::here("R", "plot.R"))
source(here::here("R", "utils.R"))

DATA_PATH <- here::here("data")
```

# Load Data {.tabset .tabset-vmodern}

Let's first load in the three datasets:

-   `qa_key`: question and answer key
-   `ling_orig`: (uncleaned) linguistics survey data
-   `zip_df`: mapping between ZIP codes and latitude/longitude coordinates

**Your task:**

-   Open `R/load.R` and fill in the code for `load_ling_data()`.

```{r load-data}
# load in data
qa_key <- load_q_and_a_key(DATA_PATH)
ling_orig <- load_ling_data(DATA_PATH)
zip_df <- load_zip_data(DATA_PATH)
```

## Quick Look {.tabset .tabset-pills .tabset-square}

Next, taking a quick look at the data...

### Q and A Data

```{r}
skimr::skim(qa_key)
```

### Linguistics Data

```{r}
skimr::skim(ling_orig)
```

### ZIP Data

```{r}
skimr::skim(zip_df)
```

# Clean Data {.tabset .tabset-vmodern}

In order to facilitate visualizations and future analyses, we will next merge the linguistics survey data with the ZIP locations data and clean the data.

**Your task:**

-   Open `R/clean.R` and fill in the code for `merge_ling_zip_data()`. This function should merge the linguistics survey data with the ZIP locations data. The goal is to relate each individual to their latitude/longitude location coordinates.

```{r}
# merge linguistics survey data with ZIP locations
ling_df <- merge_ling_zip_data(ling_orig, zip_df)
skimr::skim(ling_df)
```

```{r}
ling_df |>
  dplyr::filter(is.na(ZIP_lat) | is.na(ZIP_long)) |>
  dplyr::distinct(ZIP, CITY, STATE)
```

**Your task:**

-   Open `R/clean.R` and fill in the code for `clean_ling_data()`. Feel free to do any data cleaning you would like here.

```{r}
# do data cleaning (if necessary)
ling_df_cleaned <- clean_ling_data(ling_df)
skimr::skim(ling_df_cleaned)
```

# Data Explorations {.tabset .tabset-vmodern}

Let's do some exploratory data analysis!

To get you started, here is a map of the survey respondents and their responses to question 50.

```{r}
plt <- plot_ling_map(ling_df, qa_key, qid = 50)
plt
```

Let's also look at several different questions side-by-side:

```{r}
qids <- c(80, 73, 110, 65)
plt_ls <- list()
for (qid in qids) {
  plt_ls[[as.character(qid)]] <- plot_ling_map(
    ling_df, qa_key, qid = qid
  )
}
plt <- patchwork::wrap_plots(plt_ls)
plt
```

There are lots of categories with very few responses. What if we collapse these rare responses into an "other" category to simplify the visualization?

```{r}
qids <- c(80, 73, 110, 65)
collapsed_out <- collapse_survey_responses(ling_df, qa_key, min_prop = 0.05)
collapsed_ling_df <- collapsed_out$ling_data
collapsed_qa_key <- collapsed_out$qa_key
plt_ls <- list()
for (qid in qids) {
  plt_ls[[as.character(qid)]] <- plot_ling_map(
    collapsed_ling_df, collapsed_qa_key, qid = qid
  ) +
    vthemes::scale_color_vmodern(discrete = TRUE)
}
plt <- patchwork::wrap_plots(plt_ls)
plt
```

Visualizing each survey data point introduces some visual bias towards regions with more responses. Here is a visualization showing the most popular response per county.

```{r}
qids <- c(80, 73, 110, 65)
plt_ls <- list()
for (qid in qids) {
  plt_ls[[as.character(qid)]] <- plot_ling_map_by_county(
    collapsed_ling_df, collapsed_qa_key, qid = qid
  ) +
    vthemes::scale_fill_vmodern(discrete = TRUE)
}
plt <- patchwork::wrap_plots(plt_ls)
plt
```

**Your task:**

-   Spend some time exploring other questions and visualizations of the data. The goal is to get a feel for what the data is like and what kind of dimension reduction/clustering analyses you might want to do in the future.

```{r}
# TO FILL IN
```

# Dimension Reduction {.tabset .tabset-vmodern}

Time to begin dimension reduction.

## Principal Components Analysis {.tabset .tabset-pills .tabset-square}

Let's start with arguably the most popular dimension reduction technique - principal components analysis (PCA) using `prcomp()`.

If we apply PCA directly to our dataset:

```{r}
# do PCA
X <- get_X_matrix(ling_df)
pca_out <- prcomp(X)
pca_plt1 <- plot_pca(
  pca_out, npcs = 2, color = get_answers(ling_df$Q059, qid = 59, qa_key)
)
pca_plt1
```

The first PC corresponds to Q59. Why? Because this question has the most number of choices, so it's encoding ranges from 0-21. Since PCA tries to find the direction that maximizes the amount of variance in our data, PCA picks up a direction that is highly aligned with the Q59 responses because of it's large range.

Let's try normalizing the X so that all the questions are on the same scale:

```{r}
pca_out <- prcomp(X, scale = TRUE)
pca_plt2 <- plot_pca(
  pca_out, npcs = 2, color = get_answers(ling_df$Q059, qid = 59, qa_key)
)
pca_plt2
```

Let's try coloring it by latitude or longitude.

```{r}
# don't plot alaska and hawaii for now; otherwise, color scale is very skewed
long <- ling_df$ZIP_long
lat <- ling_df$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
plt <- patchwork::wrap_plots(
  plot_pca(pca_out, npcs = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_pca(pca_out, npcs = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
plt
```

But this still doesn't show much of a pattern with the geography of the US, which we would expect from our EDA. Why? The numeric encoding of categories imposes an ordering and distance between the categories which doesn't really make sense. In other words, if "you" = 1, "y'all" = 2, and "you guys" = 3, then this encoding implies that "you" and "you guys" is twice as different as "you" and "y'all" or "y'all" and "you guys", but this is not necessarily true.

```{r}
plt <- plot_dr_map(pca_out$x, ling_df)
plt
```

The issue is thus encoding the categorical variables directly to a number. An alternative approach is to one-hot encode these categorical responses.

```{r}
X <- one_hot_ling_data(ling_df)
pca_out <- prcomp(X)
pca_plt3 <- plot_pca(
  pca_out, npcs = 2, color = get_answers(ling_df$Q059, qid = 59, qa_key)
)
pca_plt3

```

But now, the first PC is essentially showing us the variation between people who responded and those who did not respond to the questions.

```{r}
num_nas <- rowSums(get_X_matrix(ling_df) == 0)
hist(num_nas)

pca_plt4 <- plot_pca(
  pca_out, npcs = 2, color = num_nas
) +
  ggplot2::labs(color = "Number of\nMissing Responses")
pca_plt4
```

Let's revise our data cleaning procedure and remove people who left too many questions unanswered and do PCA. We'll color the points by their latitude/longitude

```{r}
ling_df_cleaned <- remove_samples(ling_df, min_answers = 50)
X <- one_hot_ling_data(ling_df_cleaned)
pca_out <- prcomp(X)

# don't plot alaska and hawaii for now; otherwise, lat/long color scale is very skewed
long <- ling_df_cleaned$ZIP_long
lat <- ling_df_cleaned$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
pca_plt5 <- patchwork::wrap_plots(
  plot_pca(pca_out, npcs = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_pca(pca_out, npcs = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
pca_plt5
```

```{r}
plt <- plot_dr_map(pca_out$x, ling_df_cleaned, ndim = 2)
plt
```

```{r}
plt <- plot_dr_map(pca_out$x, ling_df_cleaned, ndim = 2, by_county = TRUE)
plt
```

The first two PCs now show some association with geographical regions in the US.

We can also check out the PC loadings to find the features that are driving the top PCs

```{r}
as.data.frame(abs(pca_out$rotation))
```

## tSNE {.tabset .tabset-pills .tabset-square}

While PCA is a linear dimension reduction method, tSNE is a non-linear dimension reduction method. To perform tSNE, we can use the `Rtsne::Rtsen()` function.

```{r}
ling_df_distinct <- ling_df |> 
  remove_samples(min_answers = 50) |> 
  # need to remove duplicates or else tsne will throw an error
  dplyr::distinct(
    dplyr::across(tidyselect::starts_with("Q")),
    .keep_all = TRUE
  )
X <- one_hot_ling_data(ling_df_distinct)
tsne_out <- Rtsne::Rtsne(X, dims = 2)

# don't plot alaska and hawaii for now; otherwise, lat/long color scale is very skewed
long <- ling_df_distinct$ZIP_long
lat <- ling_df_distinct$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
tsne_plt1 <- patchwork::wrap_plots(
  plot_dr_scatter(tsne_out$Y, ndim = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_dr_scatter(tsne_out$Y, ndim = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
tsne_plt1

tsne_map1 <- plot_dr_map(tsne_out$Y, ling_data = ling_df_distinct, ndim = 2)
tsne_map1

tsne_county_map1 <- plot_dr_map(tsne_out$Y, ling_data = ling_df_distinct, ndim = 2, by_county = TRUE)
tsne_county_map1
```

What is we had applied tSNE to the survey data, where we had aggregated survey responses by county?

```{r}
ling_df_agg <- ling_df |> 
  remove_samples(min_answers = 50) |> 
  one_hot_ling_data(return_matrix = FALSE) |> 
  aggregate_survey_response_by_county()

ling_df_agg_distinct <- ling_df_agg |> 
  # need to remove duplicates or else tsne will throw an error
  dplyr::distinct(
    dplyr::across(tidyselect::starts_with("Q")),
    .keep_all = TRUE
  )
X <- get_X_matrix(ling_df_agg_distinct)
tsne_out <- Rtsne::Rtsne(X)

# don't plot alaska and hawaii for now; otherwise, lat/long color scale is very skewed
long <- ling_df_agg_distinct$ZIP_long
lat <- ling_df_agg_distinct$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
tsne_plt2 <- patchwork::wrap_plots(
  plot_dr_scatter(tsne_out$Y, ndim = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_dr_scatter(tsne_out$Y, ndim = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
tsne_plt2

tsne_map2 <- plot_dr_map(tsne_out$Y, ling_data = ling_df_agg_distinct, ndim = 2, by_county = TRUE)
tsne_map2
```

## UMAP {.tabset .tabset-pills .tabset-square}

Similar to tSNE, UMAP is a non-linear dimension reduction method. To perform UMAP, we can use the `umap::umap()` function.

```{r}
X <- one_hot_ling_data(ling_df_distinct)
umap_out <- umap::umap(X)

# don't plot alaska and hawaii for now; otherwise, lat/long color scale is very skewed
long <- ling_df_distinct$ZIP_long
lat <- ling_df_distinct$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
umap_plt1 <- patchwork::wrap_plots(
  plot_dr_scatter(umap_out$layout, ndim = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_dr_scatter(umap_out$layout, ndim = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
umap_plt1

umap_map1 <- plot_dr_map(umap_out$layout, ling_data = ling_df_distinct, ndim = 2)
umap_map1

umap_county_map1 <- plot_dr_map(umap_out$layout, ling_data = ling_df_distinct, ndim = 2, by_county = TRUE)
umap_county_map1
```

What is we had applied UMAP to the survey data, where we had aggregated survey responses by county?

```{r}
X <- get_X_matrix(ling_df_agg_distinct)
umap_out <- umap::umap(X)

umap_params <- umap::umap.defaults
umap_params$n_components <- 4
umap_out <- umap::umap(X, config = umap_params)

# don't plot alaska and hawaii for now; otherwise, lat/long color scale is very skewed
long <- ling_df_agg_distinct$ZIP_long
lat <- ling_df_agg_distinct$ZIP_lat
long[lat > 130] <- NA
lat[lat > 130] <- NA
umap_plt2 <- patchwork::wrap_plots(
  plot_dr_scatter(umap_out$layout, ndim = 2, color = lat) +
    ggplot2::labs(color = "Latitude"),
  plot_dr_scatter(umap_out$layout, ndim = 2, color = long) +
    ggplot2::labs(color = "Longitude")
)
umap_plt2

umap_map2 <- plot_dr_map(umap_out$layout, ling_data = ling_df_agg_distinct, ndim = ncol(umap_out$layout), by_county = TRUE)
umap_map2
```

## Non-negative matrix factorization (NMF) {.tabset .tabset-pills .tabset-square}

NMF is a linear dimension reduction method that can be applied to non-negative data. Our data is non-negative, so it could be interesting to try this method out to see if exploiting this non-negative structure helps with the dimension reduction. To perform NMF, we can use the `NMF::nmf()` function.

```{r}
X <- get_X_matrix(ling_df_agg)
nmf_out <- NMF::nmf(X, rank = 4)

# X = WH
w <- nmf_out@fit@W # n x k matrix
h <- nmf_out@fit@H # k x p matrix

nmf_map1 <- plot_dr_map(w, ling_data = ling_df_agg, ndim = 4, by_county = TRUE)
nmf_map1
```
